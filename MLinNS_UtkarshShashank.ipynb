{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import  load_model\n",
    "import argparse, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import csv\n",
    "#import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "from itertools import groupby\n",
    "import scipy.sparse.linalg as spl\n",
    "from scipy.cluster.hierarchy import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Elements: 86, Num Environments: 83034\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get the unsupervised representations\n",
    "\"\"\"\n",
    "\n",
    "num_components = 5 # Number of components to use after PCA\n",
    "\n",
    "def readComponent(comps):\n",
    "    namelist = []\n",
    "    numlist = []\n",
    "    ccomps = comps\n",
    "    while(len(ccomps) != 0):\n",
    "        stemp = ccomps[1:]\n",
    "        if(len(stemp) == 0):\n",
    "            namelist.append(ccomps)\n",
    "            numlist.append(1.0)\n",
    "            break\n",
    "        it = 0\n",
    "        for st in stemp:\n",
    "            it = it + 1\n",
    "            if(st.isupper()):\n",
    "                im = 0\n",
    "                for mt in stemp[:it]:\n",
    "                    im = im + 1\n",
    "                    if(mt.isdigit()):\n",
    "                        namelist.append(ccomps[0:im])\n",
    "                        numlist.append(float(ccomps[im:it]))\n",
    "                        ccomps = ccomps[it:]\n",
    "                        break\n",
    "                    elif(im == len(stemp[:it])):\n",
    "                        namelist.append(ccomps[0:im])\n",
    "                        numlist.append(1.0)\n",
    "                        ccomps = ccomps[it:]\n",
    "                        break\n",
    "                break\n",
    "            elif(it == len(stemp)):\n",
    "                im = 0\n",
    "                for mt in stemp:\n",
    "                    im = im + 1\n",
    "                    if(mt.isdigit()):\n",
    "                        namelist.append(ccomps[0:im])\n",
    "                        numlist.append(float(ccomps[im:]))\n",
    "                        ccomps = ccomps[it+1:]\n",
    "                        break\n",
    "                    elif(im == len(stemp)):\n",
    "                        namelist.append(ccomps)\n",
    "                        numlist.append(1.0)\n",
    "                        ccomps = ccomps[it+1:]\n",
    "                        break\n",
    "                break\n",
    "    return namelist, numlist\n",
    "\n",
    "def get_atom_environment_pair(compound):\n",
    "    namelist, numlist = readComponent(compound)\n",
    "    atom_environment_pair = []\n",
    "    for i, element in enumerate(namelist):\n",
    "        environment = str(numlist[i])\n",
    "        for j, other_elem in enumerate(namelist):\n",
    "            if other_elem != element:\n",
    "                environment += other_elem + str(numlist[j])\n",
    "\n",
    "        atom_environment_pair.append((element, environment))    \n",
    "    return atom_environment_pair\n",
    "\n",
    "atom_environment_pairs = []\n",
    "num_compounds = 0\n",
    "\n",
    "#f = np.load('data/tc_mat_clean2.npy')\n",
    "with open('data/feature_learn.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        compound = line[0]\n",
    "        #print(compound)\n",
    "        atom_environment_pair = get_atom_environment_pair(compound)\n",
    "        atom_environment_pairs.extend(atom_environment_pair)\n",
    "        num_compounds += 1\n",
    "#for line in f:\n",
    "#    compound, target = line#.split()\n",
    "#    atom_environment_pair = get_atom_environment_pair(compound)\n",
    "#    atom_environment_pairs.extend(atom_environment_pair)\n",
    "#    num_compounds += 1\n",
    "\n",
    "environment_set = set()\n",
    "element_set = set()\n",
    "\n",
    "for atom, environment in atom_environment_pairs:\n",
    "    element_set.add(atom)\n",
    "    environment_set.add(environment)\n",
    "\n",
    "environment_set = list(environment_set)\n",
    "element_set = list(element_set)\n",
    "print(\"Num Elements: {}, Num Environments: {}\".format(len(element_set), len(environment_set)))\n",
    "\n",
    "atom_env = np.zeros((len(element_set), len(environment_set)))\n",
    "\n",
    "p = 2.0\n",
    "for idx1, ele in enumerate(element_set):\n",
    "    for idx2, env in enumerate(environment_set):\n",
    "        env_split = [''.join(x) for _, x in groupby(env, str.isalpha)]\n",
    "        if ele in env_split:\n",
    "            atom_env[idx1][idx2] = 1.\n",
    "    norm = np.sum(atom_env[idx1]**p)**(1./p)\n",
    "    atom_env[idx1]=atom_env[idx1]/norm\n",
    "\n",
    "def SVD(m):\n",
    "    u, s, vt = spl.svds(m, k=min(m.shape)-1)\n",
    "    return u, s, vt\n",
    "\n",
    "def PCA(m, k=10):\n",
    "    u, s, vt = SVD(m)\n",
    "    pc = np.matmul(u[:, :k], np.diag(s)[:k, :k])\n",
    "    pa = vt[:k, :]\n",
    "    rx = np.matmul(pc, pa)\n",
    "    return pc, pa, rx\n",
    "\n",
    "f_matrix, v_matrix, red_atom_env = PCA(atom_env, num_components)\n",
    "\n",
    "elem2idx = {}\n",
    "for i, elem in enumerate(element_set):\n",
    "    elem2idx[elem] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the representation\n",
    "\"\"\"\n",
    "\n",
    "ChemicalSymbols = [ 'X',  'H',  'He', 'Li', 'Be','B',  'C',  'N',  'O',  'F',\n",
    "                    'Ne', 'Na', 'Mg', 'Al', 'Si','P',  'S',  'Cl', 'Ar', 'K',\n",
    "                    'Ca', 'Sc', 'Ti', 'V',  'Cr','Mn', 'Fe', 'Co', 'Ni', 'Cu',\n",
    "                    'Zn', 'Ga', 'Ge', 'As', 'Se','Br', 'Kr', 'Rb', 'Sr', 'Y',\n",
    "                    'Zr', 'Nb', 'Mo', 'Tc', 'Ru','Rh', 'Pd', 'Ag', 'Cd', 'In',\n",
    "                    'Sn', 'Sb', 'Te', 'I',  'Xe','Cs', 'Ba', 'La', 'Ce', 'Pr',\n",
    "                    'Nd', 'Pm', 'Sm', 'Eu', 'Gd','Tb', 'Dy', 'Ho', 'Er', 'Tm',\n",
    "                    'Yb', 'Lu', 'Hf', 'Ta', 'W','Re', 'Os', 'Ir', 'Pt', 'Au',\n",
    "                    'Hg', 'Tl', 'Pb', 'Bi', 'Po','At', 'Rn', 'Fr', 'Ra', 'Ac',\n",
    "                    'Th', 'Pa', 'U',  'Np', 'Pu','Am', 'Cm', 'Bk', 'Cf', 'Es',\n",
    "                    'Fm', 'Md', 'No', 'Lr']\n",
    "\n",
    "atomicPeriod = [0, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
    "                2, 3, 3, 3, 3, 3, 3, 3, 3, 4,\n",
    "                4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "                4, 4, 4, 4, 4, 4, 4, 5, 5, 5,\n",
    "                5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
    "                5, 5, 5, 5, 5, 6, 6, 6, 6, 6,\n",
    "                6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
    "                6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
    "                6, 6, 6, 6, 6, 6, 6, 7, 7, 7,\n",
    "                7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
    "                7, 7, 7, 7]\n",
    "\n",
    "atomicGroup = [0,  1, 18,  1,  2, 13, 14, 15, 16, 17,\n",
    "              18,  1,  2, 13, 14, 15, 16, 17, 18,  1,\n",
    "               2,  3,  4,  5,  6,  7,  8,  9, 10, 11,\n",
    "              12, 13, 14, 15, 16, 17, 18,  1,  2,  3,\n",
    "               4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
    "              14, 15, 16, 17, 18,  1,  2,  3,  3,  3,\n",
    "               3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
    "               3,  3,  4,  5,  6,  7,  8,  9, 10, 11,\n",
    "              12, 13, 14, 15, 16, 17, 18,  1,  2,  3,\n",
    "               3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
    "               3,  3,  3,  3]\n",
    "\n",
    "atomicNum = {}\n",
    "for anum, symbol in enumerate(ChemicalSymbols):\n",
    "    atomicNum[symbol] = anum\n",
    "\n",
    "class atom:\n",
    "    def __init__(self, symbol, num=1):\n",
    "        self.name = symbol\n",
    "        self.atomicNum = atomicNum[symbol]\n",
    "        self.atomicPeriod = atomicPeriod[atomicNum[symbol]]\n",
    "        self.atomicGroup = atomicGroup[atomicNum[symbol]]\n",
    "        self.num = num\n",
    "        elem_idx = elem2idx[symbol]\n",
    "        self.element_vec = f_matrix[elem_idx, :]\n",
    "\n",
    "def get_component_vector(comps):\n",
    "    namelist, numlist = readComponent(comps)\n",
    "    avector = np.zeros((10, 10, num_components + 1))\n",
    "    asum = sum(numlist)\n",
    "\n",
    "    for i in range(len(namelist)):\n",
    "        at = atom(namelist[i])\n",
    "        idx = at.atomicNum - 1\n",
    "        r_idx = idx // 10\n",
    "        c_idx = idx % 10\n",
    "        avector[r_idx, c_idx, 0] = numlist[i] / asum\n",
    "        avector[r_idx, c_idx, 1:] = at.element_vec\n",
    "\n",
    "    return avector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "#f = np.load('data/tc_mat_clean2.npy')\n",
    "#for line in f:\n",
    "with open('data/feature_learn.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        compound, target = line\n",
    "        namelist, numlist = readComponent(compound)\n",
    "        X.append(get_component_vector(compound))\n",
    "        y.append(target)\n",
    "\n",
    "X = np.stack(X)\n",
    "y = np.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.layers.core import Dropout, Flatten, Dense, Activation\n",
    "\n",
    "def ATCNN_Tc_model():\n",
    "\n",
    "    input_shape = (10,10,6)\n",
    "    model = Sequential()\n",
    "\n",
    "    # layer1 \n",
    "    model.add(Conv2D(64, kernel_size=(5, 5), padding='same',input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # layer2\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # layer3\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # layer4\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # layer5\n",
    "    model.add(Conv2D(64, kernel_size=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # layer6\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200))\n",
    "\n",
    "    # layer7\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(100))\n",
    "\n",
    "    # layer8\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # layer9\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    \n",
    "\n",
    "    model.compile(loss=keras.losses.mean_absolute_error,\n",
    "            optimizer= keras.optimizers.Adadelta())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 64)        9664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 10, 10, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               320200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 480,033\n",
      "Trainable params: 478,665\n",
      "Non-trainable params: 1,368\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = ATCNN_Tc_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19286 samples, validate on 394 samples\n",
      "Epoch 1/100\n",
      "19286/19286 [==============================] - 9s 483us/step - loss: 13.5379 - val_loss: 19.6030\n",
      "Epoch 2/100\n",
      "19286/19286 [==============================] - 8s 404us/step - loss: 7.0999 - val_loss: 19.2739\n",
      "Epoch 3/100\n",
      "19286/19286 [==============================] - 8s 405us/step - loss: 6.5658 - val_loss: 14.8570\n",
      "Epoch 4/100\n",
      "19286/19286 [==============================] - 8s 405us/step - loss: 6.2868 - val_loss: 6.0517\n",
      "Epoch 5/100\n",
      "19286/19286 [==============================] - 8s 407us/step - loss: 5.9699 - val_loss: 6.4558\n",
      "Epoch 6/100\n",
      "19286/19286 [==============================] - 8s 403us/step - loss: 5.9339 - val_loss: 5.2158\n",
      "Epoch 7/100\n",
      "19286/19286 [==============================] - 8s 410us/step - loss: 5.7398 - val_loss: 5.7915\n",
      "Epoch 8/100\n",
      "19286/19286 [==============================] - 8s 417us/step - loss: 5.5865 - val_loss: 5.1861\n",
      "Epoch 9/100\n",
      "19286/19286 [==============================] - 8s 423us/step - loss: 5.5578 - val_loss: 5.3172\n",
      "Epoch 10/100\n",
      "19286/19286 [==============================] - 8s 421us/step - loss: 5.5004 - val_loss: 4.8800\n",
      "Epoch 11/100\n",
      "19286/19286 [==============================] - 8s 422us/step - loss: 5.4422 - val_loss: 5.6196\n",
      "Epoch 12/100\n",
      "19286/19286 [==============================] - 8s 423us/step - loss: 5.3152 - val_loss: 5.9331\n",
      "Epoch 13/100\n",
      "19286/19286 [==============================] - 8s 423us/step - loss: 5.2955 - val_loss: 5.1199\n",
      "Epoch 14/100\n",
      "19286/19286 [==============================] - 8s 421us/step - loss: 5.1862 - val_loss: 4.9136\n",
      "Epoch 15/100\n",
      "19286/19286 [==============================] - 9s 445us/step - loss: 5.1963 - val_loss: 5.1847\n",
      "Epoch 16/100\n",
      "19286/19286 [==============================] - 9s 442us/step - loss: 5.1195 - val_loss: 5.0632\n",
      "Epoch 17/100\n",
      "19286/19286 [==============================] - 10s 542us/step - loss: 5.0075 - val_loss: 5.6194\n",
      "Epoch 18/100\n",
      "19286/19286 [==============================] - 18s 934us/step - loss: 5.1178 - val_loss: 4.8663\n",
      "Epoch 19/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.9755 - val_loss: 5.1198\n",
      "Epoch 20/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.9711 - val_loss: 5.0432\n",
      "Epoch 21/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.9587 - val_loss: 5.1757\n",
      "Epoch 22/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.9195 - val_loss: 4.9900\n",
      "Epoch 23/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.8867 - val_loss: 4.8971\n",
      "Epoch 24/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.7829 - val_loss: 5.1976\n",
      "Epoch 25/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.8128 - val_loss: 4.7830\n",
      "Epoch 26/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.7612 - val_loss: 5.2020\n",
      "Epoch 27/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.7388 - val_loss: 4.8698\n",
      "Epoch 28/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.6453 - val_loss: 4.8249\n",
      "Epoch 29/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.7062 - val_loss: 5.0573\n",
      "Epoch 30/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.5392 - val_loss: 4.9465\n",
      "Epoch 31/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.6730 - val_loss: 4.6379\n",
      "Epoch 32/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.5417 - val_loss: 5.0850\n",
      "Epoch 33/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.5247 - val_loss: 4.8023\n",
      "Epoch 34/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.5524 - val_loss: 4.7172\n",
      "Epoch 35/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.5860 - val_loss: 4.4855\n",
      "Epoch 36/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.5315 - val_loss: 4.8053\n",
      "Epoch 37/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.5744 - val_loss: 4.9584\n",
      "Epoch 38/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.4347 - val_loss: 4.7939\n",
      "Epoch 39/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.4070 - val_loss: 4.9690\n",
      "Epoch 40/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.5151 - val_loss: 4.7261\n",
      "Epoch 41/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.4084 - val_loss: 4.8524\n",
      "Epoch 42/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.3872 - val_loss: 4.7920\n",
      "Epoch 43/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.3436 - val_loss: 4.7482\n",
      "Epoch 44/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.2906 - val_loss: 4.6463\n",
      "Epoch 45/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.3635 - val_loss: 4.4255\n",
      "Epoch 46/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.2430 - val_loss: 4.9141\n",
      "Epoch 47/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.2250 - val_loss: 4.8204\n",
      "Epoch 48/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.1993 - val_loss: 4.9987\n",
      "Epoch 49/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.2489 - val_loss: 4.6106\n",
      "Epoch 50/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.1402 - val_loss: 4.9194\n",
      "Epoch 51/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.0782 - val_loss: 4.8269\n",
      "Epoch 52/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.2336 - val_loss: 4.5762\n",
      "Epoch 53/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.1756 - val_loss: 4.3546\n",
      "Epoch 54/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.0542 - val_loss: 4.7742\n",
      "Epoch 55/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.1403 - val_loss: 4.8598\n",
      "Epoch 56/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.1144 - val_loss: 4.4374\n",
      "Epoch 57/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.1051 - val_loss: 4.6674\n",
      "Epoch 58/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.1154 - val_loss: 4.4223\n",
      "Epoch 59/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.0231 - val_loss: 4.5858\n",
      "Epoch 60/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.0358 - val_loss: 4.7848\n",
      "Epoch 61/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 3.9993 - val_loss: 4.7451\n",
      "Epoch 62/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 3.9794 - val_loss: 4.6881\n",
      "Epoch 63/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 4.0019 - val_loss: 4.6293\n",
      "Epoch 64/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 3.8786 - val_loss: 4.7519\n",
      "Epoch 65/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 3.8937 - val_loss: 4.5323\n",
      "Epoch 66/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 4.0128 - val_loss: 4.5852\n",
      "Epoch 67/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 3.8924 - val_loss: 4.7330\n",
      "Epoch 68/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 3.9785 - val_loss: 4.5711\n",
      "Epoch 69/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 3.9166 - val_loss: 4.5631\n",
      "Epoch 70/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 3.8766 - val_loss: 4.5680\n",
      "Epoch 71/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 3.9516 - val_loss: 4.4081\n",
      "Epoch 72/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 3.8284 - val_loss: 4.5528\n",
      "Epoch 73/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 3.8116 - val_loss: 4.2095\n",
      "Epoch 74/100\n",
      "19286/19286 [==============================] - 21s 1ms/step - loss: 3.7970 - val_loss: 4.4146\n",
      "Epoch 75/100\n",
      "19286/19286 [==============================] - 22s 1ms/step - loss: 3.8350 - val_loss: 4.5175\n",
      "Epoch 76/100\n",
      "19286/19286 [==============================] - 23s 1ms/step - loss: 3.8686 - val_loss: 4.3825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.7634 - val_loss: 4.6235\n",
      "Epoch 78/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.7881 - val_loss: 4.4140\n",
      "Epoch 79/100\n",
      "19286/19286 [==============================] - 26s 1ms/step - loss: 3.7783 - val_loss: 4.6145\n",
      "Epoch 80/100\n",
      "19286/19286 [==============================] - 26s 1ms/step - loss: 3.8103 - val_loss: 4.7715\n",
      "Epoch 81/100\n",
      "19286/19286 [==============================] - 26s 1ms/step - loss: 3.7328 - val_loss: 4.4326\n",
      "Epoch 82/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.7545 - val_loss: 4.2018\n",
      "Epoch 83/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.7309 - val_loss: 4.2983\n",
      "Epoch 84/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.6917 - val_loss: 4.8463\n",
      "Epoch 85/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.7714 - val_loss: 4.5046\n",
      "Epoch 86/100\n",
      "19286/19286 [==============================] - 26s 1ms/step - loss: 3.7141 - val_loss: 4.2278\n",
      "Epoch 87/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.6605 - val_loss: 4.5918\n",
      "Epoch 88/100\n",
      "19286/19286 [==============================] - 26s 1ms/step - loss: 3.6872 - val_loss: 4.5348\n",
      "Epoch 89/100\n",
      "19286/19286 [==============================] - 26s 1ms/step - loss: 3.6950 - val_loss: 4.6471\n",
      "Epoch 90/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.7066 - val_loss: 4.4927\n",
      "Epoch 91/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.6859 - val_loss: 4.6297\n",
      "Epoch 92/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.7157 - val_loss: 4.6073\n",
      "Epoch 93/100\n",
      "19286/19286 [==============================] - 26s 1ms/step - loss: 3.6438 - val_loss: 4.4180\n",
      "Epoch 94/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.6689 - val_loss: 4.1958\n",
      "Epoch 95/100\n",
      "19286/19286 [==============================] - 26s 1ms/step - loss: 3.6602 - val_loss: 4.2275\n",
      "Epoch 96/100\n",
      "19286/19286 [==============================] - 26s 1ms/step - loss: 3.6279 - val_loss: 4.5070\n",
      "Epoch 97/100\n",
      "19286/19286 [==============================] - 26s 1ms/step - loss: 3.6714 - val_loss: 4.1344\n",
      "Epoch 98/100\n",
      "19286/19286 [==============================] - 26s 1ms/step - loss: 3.5930 - val_loss: 4.5630\n",
      "Epoch 99/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.5710 - val_loss: 4.5638\n",
      "Epoch 100/100\n",
      "19286/19286 [==============================] - 25s 1ms/step - loss: 3.6343 - val_loss: 4.6639\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.02, batch_size=128, epochs=100)\n",
    "model.save('model1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4921/4921 [==============================] - 2s 394us/step\n",
      "test set loss: 4.028872994140163\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, y_test, batch_size=128)\n",
    "y_calc = model.predict(X_test, batch_size=128)\n",
    "print('test set loss:',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_name(compound):\n",
    "    elem_set = []\n",
    "    dec = [''.join(x) for _, x in groupby(compound, str.isalpha)]\n",
    "    for i in dec:\n",
    "        try: \n",
    "            float(i)\n",
    "        except:  \n",
    "            for j in re.findall('[A-Z][^A-Z]*', i):\n",
    "                elem_set.append(j)\n",
    "    return elem_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_based_sc_x = []\n",
    "fe_based_sc_y = []\n",
    "cu_based_sc_x = []\n",
    "cu_based_sc_y = []\n",
    "bcs_sc_x = []\n",
    "bcs_sc_y = []\n",
    "others_sc_x = []\n",
    "others_sc_y = []\n",
    "\n",
    "f = np.load('data/tc_mat_clean2.npy')\n",
    "ax = f[:,0]\n",
    "ay = f[:,1]\n",
    "\n",
    "ax_train, ax_test, ay_train, ay_test = train_test_split(ax, ay, test_size=0.2, random_state=42)\n",
    "\n",
    "for compound, target in zip(ax_test, ay_test):\n",
    "    #print(compound,target)\n",
    "    nm = atom_name(compound)\n",
    "    \n",
    "    if 'Fe' in nm and 'Cu' in nm:\n",
    "        others_sc_x.append(get_component_vector(compound))\n",
    "        others_sc_y.append(target)\n",
    "    elif 'Fe' in nm:\n",
    "        fe_based_sc_x.append(get_component_vector(compound))\n",
    "        fe_based_sc_y.append(target)\n",
    "    elif 'Cu' in nm:\n",
    "        cu_based_sc_x.append(get_component_vector(compound))\n",
    "        cu_based_sc_y.append(target)\n",
    "    elif 'Fe' not in nm and 'Cu' not in nm:\n",
    "        bcs_sc_x.append(get_component_vector(compound))\n",
    "        bcs_sc_y.append(target)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_based_sc_x = np.asarray(fe_based_sc_x)\n",
    "fe_based_sc_y = np.asarray(fe_based_sc_y)\n",
    "cu_based_sc_x = np.asarray(cu_based_sc_x)\n",
    "cu_based_sc_y = np.asarray(cu_based_sc_y)\n",
    "bcs_sc_x = np.asarray(bcs_sc_x)\n",
    "bcs_sc_y = np.asarray(bcs_sc_y)\n",
    "others_sc_x = np.asarray(others_sc_x)\n",
    "others_sc_y = np.asarray(others_sc_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282, 10, 10, 6)\n",
      "(1156, 10, 10, 6)\n",
      "(1215, 10, 10, 6)\n",
      "(67, 10, 10, 6)\n"
     ]
    }
   ],
   "source": [
    "print(fe_based_sc_x.shape)\n",
    "print(cu_based_sc_x.shape)\n",
    "print(bcs_sc_x.shape)\n",
    "print(others_sc_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 336us/step\n",
      "1156/1156 [==============================] - 0s 363us/step\n",
      "1215/1215 [==============================] - 0s 346us/step\n",
      "67/67 [==============================] - 0s 506us/step\n"
     ]
    }
   ],
   "source": [
    "loss1 = model.evaluate(fe_based_sc_x, fe_based_sc_y, batch_size=128)\n",
    "calc1 = model.predict(fe_based_sc_x, batch_size=128)\n",
    "loss2 = model.evaluate(cu_based_sc_x, cu_based_sc_y, batch_size=128)\n",
    "calc2 = model.predict(cu_based_sc_x, batch_size=128)\n",
    "loss3 = model.evaluate(bcs_sc_x, bcs_sc_y, batch_size=128)\n",
    "calc3 = model.predict(bcs_sc_x, batch_size=128)\n",
    "loss4 = model.evaluate(others_sc_x, others_sc_y, batch_size=128)\n",
    "calc4 = model.predict(others_sc_x, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.873446259944084\n",
      "3.7606631441319243\n",
      "10.76606559753418\n",
      "1.2371067647580747\n"
     ]
    }
   ],
   "source": [
    "print(loss2)\n",
    "print(loss1)\n",
    "print(loss4)\n",
    "print(loss3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.2431262],\n",
       "       [36.85376  ],\n",
       "       [ 4.9418726],\n",
       "       [85.01143  ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd = ['Hg1', 'Mg1B2', 'Fe1Se1', 'Y1Ba2Cu3O7']\n",
    "px = []\n",
    "for i in prd:\n",
    "    px.append(get_component_vector(i))\n",
    "model.predict(np.asarray(px), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
